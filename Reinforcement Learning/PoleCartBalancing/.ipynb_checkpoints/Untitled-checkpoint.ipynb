{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32375512-cc22-464d-80e9-1e434903f41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.3'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym #Environment\n",
    "\n",
    "#Policy \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "import math\n",
    "import numpy\n",
    "\n",
    "from collections import deque #For replay buffer\n",
    "torch.set_default_device('cpu')#'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.get_default_device()\n",
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "995af99b-1044-4492-9fc3-dd3ae0a7a0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rl_env\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['CONDA_DEFAULT_ENV']) # checking current environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24183164-e92a-4688-9613-678d9a5750c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99       # Discount Factor\n",
    "LR = 0.001         # Learning Rate\n",
    "BATCH_SIZE = 64    # Batch Size for Training\n",
    "EPSILON = 1.0      # Exploration Rate\n",
    "EPSILON_MIN = 0.01 # Minimum Exploration Rate\n",
    "EPSILON_DECAY = 0.995 # Exploration Decay\n",
    "MEMORY_SIZE = 10000  # Replay Buffer Size\n",
    "TARGET_UPDATE = 10  # Update Target Network Every X Episodes\n",
    "MEMORY_SIZE = 10000  # Replay Buffer Size\n",
    "TARGET_UPDATE = 10  # Update Target Network Every X Episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0bf34b4d-7b89-4af3-9c28-dcfb838a0b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dbf2b080-2afd-444c-9ba3-fbce77ae5b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STATE_SIZE = env.observation_space.shape[0] #ordered set (cart position, cart velocity, pole angle, and pole angular velocity)\n",
    "ACTION_SIZE = env.action_space.n #LEFT or RIGHT\n",
    "STATE_SIZE, ACTION_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c372244-c955-4875-91a3-34d70a5cca26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cbf86144-f91d-4fe7-8adb-f915e41cf929",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_space_size, action_space_size, hidden_units):\n",
    "        super(DQN, self).__init__()\n",
    "        self.state_space_size = state_space_size\n",
    "        self.action_space_size = action_space_size\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(state_space_size, hidden_units),\n",
    "            nn.Linear(hidden_units, hidden_units),\n",
    "            nn.Linear(hidden_units, action_space_size)\n",
    "        )\n",
    "\n",
    "    def forward(self,state):\n",
    "        x = self.block(state)\n",
    "        return x\n",
    "dqn = DQN(STATE_SIZE,ACTION_SIZE, 24) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "166703bd-4440-4948-a081-ea4526d27e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    def sample(self, batch_size): #Random sampling\n",
    "        return random.sample(self.buffer, batch_size) \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "memory = ReplayBuffer(MEMORY_SIZE)\n",
    "len(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f2cf3156-a860-42b7-9e31-ad522e31fa8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2707, -0.0274]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.FloatTensor(env.reset()[0]).unsqueeze(dim=0)\n",
    "dqn(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "332d9e08-90fa-4eaa-b7a3-90a83e459e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    if len(memory) < BATCH_SIZE: #To chekc if theres enough experience\n",
    "        return\n",
    "\n",
    "    batch = memory.sample(BATCH_SIZE)\n",
    "    states, actions, rewards, next_states, dones = zip(*batch)\n",
    "    # print(states)\n",
    "    \n",
    "    states = torch.FloatTensor(states)\n",
    "    actions = torch.LongTensor(actions).unsqueeze(1)\n",
    "    rewards = torch.FloatTensor(rewards)\n",
    "    next_states = torch.FloatTensor(next_states)\n",
    "    dones = torch.FloatTensor(dones)\n",
    "\n",
    "    current_q_values = policy_net(states).gather(1, actions).squeeze()\n",
    "\n",
    "    next_q_values = target_net(next_states).max(1)[0].detach()\n",
    "    expected_q_values = rewards + GAMMA * next_q_values * (1 - dones)\n",
    "\n",
    "    loss = torch.nn.functional.mse_loss(current_q_values, expected_q_values)\n",
    "\n",
    "    optimizer.zero_grad()  # Reset gradients\n",
    "    loss.backward()        # Compute gradients\n",
    "    optimizer.step()       # Update weights\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "61540446-6d2e-42ea-933e-d8899ffcfa5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: Total Reward = 17.0\n",
      "Episode 1: Total Reward = 11.0\n",
      "Episode 2: Total Reward = 10.0\n",
      "Episode 3: Total Reward = 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91748\\AppData\\Local\\Temp\\ipykernel_27876\\1137583771.py:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  states = torch.FloatTensor(states)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4: Total Reward = 11.0\n",
      "Episode 5: Total Reward = 40.0\n",
      "Episode 6: Total Reward = 13.0\n",
      "Episode 7: Total Reward = 21.0\n",
      "Episode 8: Total Reward = 17.0\n",
      "Episode 9: Total Reward = 13.0\n",
      "Episode 10: Total Reward = 17.0\n",
      "Episode 11: Total Reward = 19.0\n",
      "Episode 12: Total Reward = 34.0\n",
      "Episode 13: Total Reward = 12.0\n",
      "Episode 14: Total Reward = 59.0\n",
      "Episode 15: Total Reward = 19.0\n",
      "Episode 16: Total Reward = 33.0\n",
      "Episode 17: Total Reward = 21.0\n",
      "Episode 18: Total Reward = 13.0\n",
      "Episode 19: Total Reward = 31.0\n",
      "Episode 20: Total Reward = 20.0\n",
      "Episode 21: Total Reward = 24.0\n",
      "Episode 22: Total Reward = 30.0\n",
      "Episode 23: Total Reward = 45.0\n",
      "Episode 24: Total Reward = 54.0\n",
      "Episode 25: Total Reward = 31.0\n",
      "Episode 26: Total Reward = 19.0\n",
      "Episode 27: Total Reward = 20.0\n",
      "Episode 28: Total Reward = 11.0\n",
      "Episode 29: Total Reward = 10.0\n",
      "Episode 30: Total Reward = 28.0\n",
      "Episode 31: Total Reward = 36.0\n",
      "Episode 32: Total Reward = 50.0\n",
      "Episode 33: Total Reward = 19.0\n",
      "Episode 34: Total Reward = 16.0\n",
      "Episode 35: Total Reward = 15.0\n",
      "Episode 36: Total Reward = 13.0\n",
      "Episode 37: Total Reward = 30.0\n",
      "Episode 38: Total Reward = 28.0\n",
      "Episode 39: Total Reward = 16.0\n",
      "Episode 40: Total Reward = 25.0\n",
      "Episode 41: Total Reward = 97.0\n",
      "Episode 42: Total Reward = 17.0\n",
      "Episode 43: Total Reward = 14.0\n",
      "Episode 44: Total Reward = 36.0\n",
      "Episode 45: Total Reward = 59.0\n",
      "Episode 46: Total Reward = 19.0\n",
      "Episode 47: Total Reward = 12.0\n",
      "Episode 48: Total Reward = 48.0\n",
      "Episode 49: Total Reward = 56.0\n",
      "Episode 50: Total Reward = 33.0\n",
      "Episode 51: Total Reward = 25.0\n",
      "Episode 52: Total Reward = 36.0\n",
      "Episode 53: Total Reward = 20.0\n",
      "Episode 54: Total Reward = 26.0\n",
      "Episode 55: Total Reward = 15.0\n",
      "Episode 56: Total Reward = 9.0\n",
      "Episode 57: Total Reward = 23.0\n",
      "Episode 58: Total Reward = 12.0\n",
      "Episode 59: Total Reward = 13.0\n",
      "Episode 60: Total Reward = 41.0\n",
      "Episode 61: Total Reward = 52.0\n",
      "Episode 62: Total Reward = 30.0\n",
      "Episode 63: Total Reward = 10.0\n",
      "Episode 64: Total Reward = 16.0\n",
      "Episode 65: Total Reward = 8.0\n",
      "Episode 66: Total Reward = 21.0\n",
      "Episode 67: Total Reward = 14.0\n",
      "Episode 68: Total Reward = 15.0\n",
      "Episode 69: Total Reward = 13.0\n",
      "Episode 70: Total Reward = 16.0\n",
      "Episode 71: Total Reward = 22.0\n",
      "Episode 72: Total Reward = 27.0\n",
      "Episode 73: Total Reward = 33.0\n",
      "Episode 74: Total Reward = 21.0\n",
      "Episode 75: Total Reward = 82.0\n",
      "Episode 76: Total Reward = 26.0\n",
      "Episode 77: Total Reward = 15.0\n",
      "Episode 78: Total Reward = 41.0\n",
      "Episode 79: Total Reward = 13.0\n",
      "Episode 80: Total Reward = 28.0\n",
      "Episode 81: Total Reward = 31.0\n",
      "Episode 82: Total Reward = 26.0\n",
      "Episode 83: Total Reward = 53.0\n",
      "Episode 84: Total Reward = 21.0\n",
      "Episode 85: Total Reward = 34.0\n",
      "Episode 86: Total Reward = 66.0\n",
      "Episode 87: Total Reward = 14.0\n",
      "Episode 88: Total Reward = 51.0\n",
      "Episode 89: Total Reward = 49.0\n",
      "Episode 90: Total Reward = 14.0\n",
      "Episode 91: Total Reward = 49.0\n",
      "Episode 92: Total Reward = 11.0\n",
      "Episode 93: Total Reward = 34.0\n",
      "Episode 94: Total Reward = 21.0\n",
      "Episode 95: Total Reward = 9.0\n",
      "Episode 96: Total Reward = 35.0\n",
      "Episode 97: Total Reward = 18.0\n",
      "Episode 98: Total Reward = 54.0\n",
      "Episode 99: Total Reward = 45.0\n",
      "Episode 100: Total Reward = 21.0\n",
      "Episode 101: Total Reward = 17.0\n",
      "Episode 102: Total Reward = 20.0\n",
      "Episode 103: Total Reward = 16.0\n",
      "Episode 104: Total Reward = 33.0\n",
      "Episode 105: Total Reward = 20.0\n",
      "Episode 106: Total Reward = 17.0\n",
      "Episode 107: Total Reward = 21.0\n",
      "Episode 108: Total Reward = 17.0\n",
      "Episode 109: Total Reward = 13.0\n",
      "Episode 110: Total Reward = 11.0\n",
      "Episode 111: Total Reward = 37.0\n",
      "Episode 112: Total Reward = 97.0\n",
      "Episode 113: Total Reward = 19.0\n",
      "Episode 114: Total Reward = 43.0\n",
      "Episode 115: Total Reward = 13.0\n",
      "Episode 116: Total Reward = 15.0\n",
      "Episode 117: Total Reward = 27.0\n",
      "Episode 118: Total Reward = 12.0\n",
      "Episode 119: Total Reward = 15.0\n",
      "Episode 120: Total Reward = 11.0\n",
      "Episode 121: Total Reward = 22.0\n",
      "Episode 122: Total Reward = 12.0\n",
      "Episode 123: Total Reward = 21.0\n",
      "Episode 124: Total Reward = 12.0\n",
      "Episode 125: Total Reward = 12.0\n",
      "Episode 126: Total Reward = 15.0\n",
      "Episode 127: Total Reward = 20.0\n",
      "Episode 128: Total Reward = 12.0\n",
      "Episode 129: Total Reward = 17.0\n",
      "Episode 130: Total Reward = 11.0\n",
      "Episode 131: Total Reward = 42.0\n",
      "Episode 132: Total Reward = 15.0\n",
      "Episode 133: Total Reward = 14.0\n",
      "Episode 134: Total Reward = 35.0\n",
      "Episode 135: Total Reward = 9.0\n",
      "Episode 136: Total Reward = 14.0\n",
      "Episode 137: Total Reward = 30.0\n",
      "Episode 138: Total Reward = 39.0\n",
      "Episode 139: Total Reward = 12.0\n",
      "Episode 140: Total Reward = 13.0\n",
      "Episode 141: Total Reward = 15.0\n",
      "Episode 142: Total Reward = 21.0\n",
      "Episode 143: Total Reward = 43.0\n",
      "Episode 144: Total Reward = 26.0\n",
      "Episode 145: Total Reward = 19.0\n",
      "Episode 146: Total Reward = 10.0\n",
      "Episode 147: Total Reward = 90.0\n",
      "Episode 148: Total Reward = 39.0\n",
      "Episode 149: Total Reward = 25.0\n",
      "Episode 150: Total Reward = 13.0\n",
      "Episode 151: Total Reward = 11.0\n",
      "Episode 152: Total Reward = 13.0\n",
      "Episode 153: Total Reward = 9.0\n",
      "Episode 154: Total Reward = 16.0\n",
      "Episode 155: Total Reward = 12.0\n",
      "Episode 156: Total Reward = 13.0\n",
      "Episode 157: Total Reward = 10.0\n",
      "Episode 158: Total Reward = 10.0\n",
      "Episode 159: Total Reward = 16.0\n",
      "Episode 160: Total Reward = 12.0\n",
      "Episode 161: Total Reward = 10.0\n",
      "Episode 162: Total Reward = 23.0\n",
      "Episode 163: Total Reward = 15.0\n",
      "Episode 164: Total Reward = 12.0\n",
      "Episode 165: Total Reward = 10.0\n",
      "Episode 166: Total Reward = 9.0\n",
      "Episode 167: Total Reward = 15.0\n",
      "Episode 168: Total Reward = 68.0\n",
      "Episode 169: Total Reward = 12.0\n",
      "Episode 170: Total Reward = 34.0\n",
      "Episode 171: Total Reward = 11.0\n",
      "Episode 172: Total Reward = 15.0\n",
      "Episode 173: Total Reward = 13.0\n",
      "Episode 174: Total Reward = 31.0\n",
      "Episode 175: Total Reward = 33.0\n",
      "Episode 176: Total Reward = 35.0\n",
      "Episode 177: Total Reward = 14.0\n",
      "Episode 178: Total Reward = 43.0\n",
      "Episode 179: Total Reward = 31.0\n",
      "Episode 180: Total Reward = 27.0\n",
      "Episode 181: Total Reward = 72.0\n",
      "Episode 182: Total Reward = 25.0\n",
      "Episode 183: Total Reward = 10.0\n",
      "Episode 184: Total Reward = 52.0\n",
      "Episode 185: Total Reward = 36.0\n",
      "Episode 186: Total Reward = 10.0\n",
      "Episode 187: Total Reward = 14.0\n",
      "Episode 188: Total Reward = 12.0\n",
      "Episode 189: Total Reward = 16.0\n",
      "Episode 190: Total Reward = 11.0\n",
      "Episode 191: Total Reward = 16.0\n",
      "Episode 192: Total Reward = 12.0\n",
      "Episode 193: Total Reward = 17.0\n",
      "Episode 194: Total Reward = 10.0\n",
      "Episode 195: Total Reward = 13.0\n",
      "Episode 196: Total Reward = 11.0\n",
      "Episode 197: Total Reward = 30.0\n",
      "Episode 198: Total Reward = 36.0\n",
      "Episode 199: Total Reward = 12.0\n",
      "Episode 200: Total Reward = 11.0\n",
      "Episode 201: Total Reward = 20.0\n",
      "Episode 202: Total Reward = 31.0\n",
      "Episode 203: Total Reward = 11.0\n",
      "Episode 204: Total Reward = 40.0\n",
      "Episode 205: Total Reward = 20.0\n",
      "Episode 206: Total Reward = 12.0\n",
      "Episode 207: Total Reward = 11.0\n",
      "Episode 208: Total Reward = 10.0\n",
      "Episode 209: Total Reward = 42.0\n",
      "Episode 210: Total Reward = 12.0\n",
      "Episode 211: Total Reward = 11.0\n",
      "Episode 212: Total Reward = 11.0\n",
      "Episode 213: Total Reward = 17.0\n",
      "Episode 214: Total Reward = 14.0\n",
      "Episode 215: Total Reward = 17.0\n",
      "Episode 216: Total Reward = 9.0\n",
      "Episode 217: Total Reward = 9.0\n",
      "Episode 218: Total Reward = 35.0\n",
      "Episode 219: Total Reward = 23.0\n",
      "Episode 220: Total Reward = 30.0\n",
      "Episode 221: Total Reward = 12.0\n",
      "Episode 222: Total Reward = 24.0\n",
      "Episode 223: Total Reward = 16.0\n",
      "Episode 224: Total Reward = 13.0\n",
      "Episode 225: Total Reward = 21.0\n",
      "Episode 226: Total Reward = 16.0\n",
      "Episode 227: Total Reward = 12.0\n",
      "Episode 228: Total Reward = 10.0\n",
      "Episode 229: Total Reward = 11.0\n",
      "Episode 230: Total Reward = 8.0\n",
      "Episode 231: Total Reward = 12.0\n",
      "Episode 232: Total Reward = 27.0\n",
      "Episode 233: Total Reward = 12.0\n",
      "Episode 234: Total Reward = 31.0\n",
      "Episode 235: Total Reward = 10.0\n",
      "Episode 236: Total Reward = 9.0\n",
      "Episode 237: Total Reward = 29.0\n",
      "Episode 238: Total Reward = 9.0\n",
      "Episode 239: Total Reward = 9.0\n",
      "Episode 240: Total Reward = 28.0\n",
      "Episode 241: Total Reward = 16.0\n",
      "Episode 242: Total Reward = 16.0\n",
      "Episode 243: Total Reward = 17.0\n",
      "Episode 244: Total Reward = 14.0\n",
      "Episode 245: Total Reward = 10.0\n",
      "Episode 246: Total Reward = 8.0\n",
      "Episode 247: Total Reward = 15.0\n",
      "Episode 248: Total Reward = 9.0\n",
      "Episode 249: Total Reward = 14.0\n",
      "Episode 250: Total Reward = 10.0\n",
      "Episode 251: Total Reward = 21.0\n",
      "Episode 252: Total Reward = 12.0\n",
      "Episode 253: Total Reward = 26.0\n",
      "Episode 254: Total Reward = 15.0\n",
      "Episode 255: Total Reward = 16.0\n",
      "Episode 256: Total Reward = 16.0\n",
      "Episode 257: Total Reward = 14.0\n",
      "Episode 258: Total Reward = 24.0\n",
      "Episode 259: Total Reward = 11.0\n",
      "Episode 260: Total Reward = 9.0\n",
      "Episode 261: Total Reward = 14.0\n",
      "Episode 262: Total Reward = 10.0\n",
      "Episode 263: Total Reward = 9.0\n",
      "Episode 264: Total Reward = 39.0\n",
      "Episode 265: Total Reward = 15.0\n",
      "Episode 266: Total Reward = 9.0\n",
      "Episode 267: Total Reward = 12.0\n",
      "Episode 268: Total Reward = 31.0\n",
      "Episode 269: Total Reward = 17.0\n",
      "Episode 270: Total Reward = 17.0\n",
      "Episode 271: Total Reward = 26.0\n",
      "Episode 272: Total Reward = 25.0\n",
      "Episode 273: Total Reward = 12.0\n",
      "Episode 274: Total Reward = 10.0\n",
      "Episode 275: Total Reward = 16.0\n",
      "Episode 276: Total Reward = 9.0\n",
      "Episode 277: Total Reward = 13.0\n",
      "Episode 278: Total Reward = 10.0\n",
      "Episode 279: Total Reward = 11.0\n",
      "Episode 280: Total Reward = 45.0\n",
      "Episode 281: Total Reward = 26.0\n",
      "Episode 282: Total Reward = 15.0\n",
      "Episode 283: Total Reward = 8.0\n",
      "Episode 284: Total Reward = 10.0\n",
      "Episode 285: Total Reward = 9.0\n",
      "Episode 286: Total Reward = 59.0\n",
      "Episode 287: Total Reward = 8.0\n",
      "Episode 288: Total Reward = 18.0\n",
      "Episode 289: Total Reward = 36.0\n",
      "Episode 290: Total Reward = 10.0\n",
      "Episode 291: Total Reward = 33.0\n",
      "Episode 292: Total Reward = 24.0\n",
      "Episode 293: Total Reward = 10.0\n",
      "Episode 294: Total Reward = 10.0\n",
      "Episode 295: Total Reward = 16.0\n",
      "Episode 296: Total Reward = 9.0\n",
      "Episode 297: Total Reward = 12.0\n",
      "Episode 298: Total Reward = 63.0\n",
      "Episode 299: Total Reward = 11.0\n",
      "Episode 300: Total Reward = 25.0\n",
      "Episode 301: Total Reward = 10.0\n",
      "Episode 302: Total Reward = 10.0\n",
      "Episode 303: Total Reward = 38.0\n",
      "Episode 304: Total Reward = 13.0\n",
      "Episode 305: Total Reward = 13.0\n",
      "Episode 306: Total Reward = 14.0\n",
      "Episode 307: Total Reward = 9.0\n",
      "Episode 308: Total Reward = 9.0\n",
      "Episode 309: Total Reward = 11.0\n",
      "Episode 310: Total Reward = 12.0\n",
      "Episode 311: Total Reward = 11.0\n",
      "Episode 312: Total Reward = 12.0\n",
      "Episode 313: Total Reward = 10.0\n",
      "Episode 314: Total Reward = 10.0\n",
      "Episode 315: Total Reward = 10.0\n",
      "Episode 316: Total Reward = 12.0\n",
      "Episode 317: Total Reward = 9.0\n",
      "Episode 318: Total Reward = 12.0\n",
      "Episode 319: Total Reward = 9.0\n",
      "Episode 320: Total Reward = 18.0\n",
      "Episode 321: Total Reward = 12.0\n",
      "Episode 322: Total Reward = 14.0\n",
      "Episode 323: Total Reward = 11.0\n",
      "Episode 324: Total Reward = 9.0\n",
      "Episode 325: Total Reward = 9.0\n",
      "Episode 326: Total Reward = 12.0\n",
      "Episode 327: Total Reward = 18.0\n",
      "Episode 328: Total Reward = 22.0\n",
      "Episode 329: Total Reward = 8.0\n",
      "Episode 330: Total Reward = 12.0\n",
      "Episode 331: Total Reward = 10.0\n",
      "Episode 332: Total Reward = 10.0\n",
      "Episode 333: Total Reward = 11.0\n",
      "Episode 334: Total Reward = 17.0\n",
      "Episode 335: Total Reward = 10.0\n",
      "Episode 336: Total Reward = 9.0\n",
      "Episode 337: Total Reward = 11.0\n",
      "Episode 338: Total Reward = 25.0\n",
      "Episode 339: Total Reward = 10.0\n",
      "Episode 340: Total Reward = 20.0\n",
      "Episode 341: Total Reward = 12.0\n",
      "Episode 342: Total Reward = 17.0\n",
      "Episode 343: Total Reward = 9.0\n",
      "Episode 344: Total Reward = 10.0\n",
      "Episode 345: Total Reward = 8.0\n",
      "Episode 346: Total Reward = 14.0\n",
      "Episode 347: Total Reward = 12.0\n",
      "Episode 348: Total Reward = 13.0\n",
      "Episode 349: Total Reward = 13.0\n",
      "Episode 350: Total Reward = 10.0\n",
      "Episode 351: Total Reward = 9.0\n",
      "Episode 352: Total Reward = 8.0\n",
      "Episode 353: Total Reward = 10.0\n",
      "Episode 354: Total Reward = 21.0\n",
      "Episode 355: Total Reward = 13.0\n",
      "Episode 356: Total Reward = 11.0\n",
      "Episode 357: Total Reward = 10.0\n",
      "Episode 358: Total Reward = 12.0\n",
      "Episode 359: Total Reward = 9.0\n",
      "Episode 360: Total Reward = 9.0\n",
      "Episode 361: Total Reward = 11.0\n",
      "Episode 362: Total Reward = 56.0\n",
      "Episode 363: Total Reward = 30.0\n",
      "Episode 364: Total Reward = 33.0\n",
      "Episode 365: Total Reward = 20.0\n",
      "Episode 366: Total Reward = 8.0\n",
      "Episode 367: Total Reward = 13.0\n",
      "Episode 368: Total Reward = 25.0\n",
      "Episode 369: Total Reward = 21.0\n",
      "Episode 370: Total Reward = 10.0\n",
      "Episode 371: Total Reward = 50.0\n",
      "Episode 372: Total Reward = 32.0\n",
      "Episode 373: Total Reward = 19.0\n",
      "Episode 374: Total Reward = 10.0\n",
      "Episode 375: Total Reward = 9.0\n",
      "Episode 376: Total Reward = 29.0\n",
      "Episode 377: Total Reward = 11.0\n",
      "Episode 378: Total Reward = 11.0\n",
      "Episode 379: Total Reward = 11.0\n",
      "Episode 380: Total Reward = 10.0\n",
      "Episode 381: Total Reward = 11.0\n",
      "Episode 382: Total Reward = 9.0\n",
      "Episode 383: Total Reward = 11.0\n",
      "Episode 384: Total Reward = 35.0\n",
      "Episode 385: Total Reward = 17.0\n",
      "Episode 386: Total Reward = 11.0\n",
      "Episode 387: Total Reward = 8.0\n",
      "Episode 388: Total Reward = 9.0\n",
      "Episode 389: Total Reward = 9.0\n",
      "Episode 390: Total Reward = 13.0\n",
      "Episode 391: Total Reward = 10.0\n",
      "Episode 392: Total Reward = 10.0\n",
      "Episode 393: Total Reward = 11.0\n",
      "Episode 394: Total Reward = 12.0\n",
      "Episode 395: Total Reward = 10.0\n",
      "Episode 396: Total Reward = 8.0\n",
      "Episode 397: Total Reward = 48.0\n",
      "Episode 398: Total Reward = 9.0\n",
      "Episode 399: Total Reward = 11.0\n",
      "Episode 400: Total Reward = 37.0\n",
      "Episode 401: Total Reward = 12.0\n",
      "Episode 402: Total Reward = 28.0\n",
      "Episode 403: Total Reward = 10.0\n",
      "Episode 404: Total Reward = 10.0\n",
      "Episode 405: Total Reward = 13.0\n",
      "Episode 406: Total Reward = 30.0\n",
      "Episode 407: Total Reward = 10.0\n",
      "Episode 408: Total Reward = 10.0\n",
      "Episode 409: Total Reward = 9.0\n",
      "Episode 410: Total Reward = 10.0\n",
      "Episode 411: Total Reward = 8.0\n",
      "Episode 412: Total Reward = 9.0\n",
      "Episode 413: Total Reward = 10.0\n",
      "Episode 414: Total Reward = 11.0\n",
      "Episode 415: Total Reward = 12.0\n",
      "Episode 416: Total Reward = 51.0\n",
      "Episode 417: Total Reward = 9.0\n",
      "Episode 418: Total Reward = 20.0\n",
      "Episode 419: Total Reward = 12.0\n",
      "Episode 420: Total Reward = 27.0\n",
      "Episode 421: Total Reward = 13.0\n",
      "Episode 422: Total Reward = 36.0\n",
      "Episode 423: Total Reward = 12.0\n",
      "Episode 424: Total Reward = 10.0\n",
      "Episode 425: Total Reward = 11.0\n",
      "Episode 426: Total Reward = 36.0\n",
      "Episode 427: Total Reward = 9.0\n",
      "Episode 428: Total Reward = 13.0\n",
      "Episode 429: Total Reward = 10.0\n",
      "Episode 430: Total Reward = 9.0\n",
      "Episode 431: Total Reward = 10.0\n",
      "Episode 432: Total Reward = 11.0\n",
      "Episode 433: Total Reward = 12.0\n",
      "Episode 434: Total Reward = 10.0\n",
      "Episode 435: Total Reward = 9.0\n",
      "Episode 436: Total Reward = 12.0\n",
      "Episode 437: Total Reward = 9.0\n",
      "Episode 438: Total Reward = 9.0\n",
      "Episode 439: Total Reward = 10.0\n",
      "Episode 440: Total Reward = 8.0\n",
      "Episode 441: Total Reward = 9.0\n",
      "Episode 442: Total Reward = 8.0\n",
      "Episode 443: Total Reward = 10.0\n",
      "Episode 444: Total Reward = 11.0\n",
      "Episode 445: Total Reward = 9.0\n",
      "Episode 446: Total Reward = 10.0\n",
      "Episode 447: Total Reward = 9.0\n",
      "Episode 448: Total Reward = 9.0\n",
      "Episode 449: Total Reward = 9.0\n",
      "Episode 450: Total Reward = 10.0\n",
      "Episode 451: Total Reward = 10.0\n",
      "Episode 452: Total Reward = 36.0\n",
      "Episode 453: Total Reward = 10.0\n",
      "Episode 454: Total Reward = 9.0\n",
      "Episode 455: Total Reward = 8.0\n",
      "Episode 456: Total Reward = 10.0\n",
      "Episode 457: Total Reward = 9.0\n",
      "Episode 458: Total Reward = 9.0\n",
      "Episode 459: Total Reward = 11.0\n",
      "Episode 460: Total Reward = 10.0\n",
      "Episode 461: Total Reward = 8.0\n",
      "Episode 462: Total Reward = 16.0\n",
      "Episode 463: Total Reward = 9.0\n",
      "Episode 464: Total Reward = 10.0\n",
      "Episode 465: Total Reward = 11.0\n",
      "Episode 466: Total Reward = 10.0\n",
      "Episode 467: Total Reward = 10.0\n",
      "Episode 468: Total Reward = 9.0\n",
      "Episode 469: Total Reward = 9.0\n",
      "Episode 470: Total Reward = 11.0\n",
      "Episode 471: Total Reward = 10.0\n",
      "Episode 472: Total Reward = 9.0\n",
      "Episode 473: Total Reward = 10.0\n",
      "Episode 474: Total Reward = 9.0\n",
      "Episode 475: Total Reward = 30.0\n",
      "Episode 476: Total Reward = 29.0\n",
      "Episode 477: Total Reward = 45.0\n",
      "Episode 478: Total Reward = 10.0\n",
      "Episode 479: Total Reward = 12.0\n",
      "Episode 480: Total Reward = 12.0\n",
      "Episode 481: Total Reward = 10.0\n",
      "Episode 482: Total Reward = 30.0\n",
      "Episode 483: Total Reward = 11.0\n",
      "Episode 484: Total Reward = 12.0\n",
      "Episode 485: Total Reward = 40.0\n",
      "Episode 486: Total Reward = 10.0\n",
      "Episode 487: Total Reward = 27.0\n",
      "Episode 488: Total Reward = 18.0\n",
      "Episode 489: Total Reward = 11.0\n",
      "Episode 490: Total Reward = 12.0\n",
      "Episode 491: Total Reward = 14.0\n",
      "Episode 492: Total Reward = 10.0\n",
      "Episode 493: Total Reward = 10.0\n",
      "Episode 494: Total Reward = 9.0\n",
      "Episode 495: Total Reward = 27.0\n",
      "Episode 496: Total Reward = 9.0\n",
      "Episode 497: Total Reward = 11.0\n",
      "Episode 498: Total Reward = 16.0\n",
      "Episode 499: Total Reward = 11.0\n"
     ]
    }
   ],
   "source": [
    "policy_net = DQN(STATE_SIZE, ACTION_SIZE, 24)\n",
    "target_net = DQN(STATE_SIZE, ACTION_SIZE, 24)\n",
    "\n",
    "target_net.load_state_dict(policy_net.state_dict())  # Copy weights\n",
    "target_net.eval()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LR)\n",
    "\n",
    "# Training Loop\n",
    "num_episodes = 500\n",
    "epsilon = EPSILON\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LR)\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "num_episodes = 500\n",
    "epsilon = EPSILON\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    state = state[0]  # Get state from tuple\n",
    "    total_reward = 0\n",
    "\n",
    "    for t in range(200):\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.random() < epsilon:\n",
    "            action = env.action_space.sample()  # Explore\n",
    "        else:\n",
    "            state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "            action = policy_net(state_tensor).argmax().item()  # Exploit\n",
    "\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        memory.push(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        \n",
    "        # Train the model\n",
    "        train_model()\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # Decay epsilon\n",
    "    epsilon = max(EPSILON_MIN, epsilon * EPSILON_DECAY)\n",
    "\n",
    "    # Update Target Network\n",
    "    if episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    print(f\"Episode {episode}: Total Reward = {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "266b6294-e74a-423e-96ae-57c9dea18bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Episode Reward: 10.0\n"
     ]
    }
   ],
   "source": [
    "def test_agent():\n",
    "    state = env.reset()\n",
    "    state = state[0]\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "        action = policy_net(state_tensor).argmax().item()\n",
    "        state, reward, done, _, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "    print(f\"Test Episode Reward: {total_reward}\")\n",
    "\n",
    "# Run the trained agent\n",
    "test_agent()\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6019abed-cf60-47b3-b5c3-a835796a1dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym[classic_control] in c:\\users\\91748\\.conda\\envs\\rl_env\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\91748\\.conda\\envs\\rl_env\\lib\\site-packages (from gym[classic_control]) (2.1.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\91748\\.conda\\envs\\rl_env\\lib\\site-packages (from gym[classic_control]) (3.1.1)\n",
      "Requirement already satisfied: gym_notices>=0.0.4 in c:\\users\\91748\\.conda\\envs\\rl_env\\lib\\site-packages (from gym[classic_control]) (0.0.8)\n",
      "Collecting pygame==2.1.0 (from gym[classic_control])\n",
      "  Using cached pygame-2.1.0.tar.gz (5.8 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [81 lines of output]\n",
      "  \n",
      "  \n",
      "  WARNING, No \"Setup\" File Exists, Running \"buildconfig/config.py\"\n",
      "  Using WINDOWS configuration...\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\91748\\AppData\\Local\\Temp\\pip-install-zh6t99wg\\pygame_2f19fb3783ad4cb6ae6eb0ba7ee53046\\buildconfig\\config_win.py\", line 336, in configure\n",
      "      from . import vstools\n",
      "    File \"C:\\Users\\91748\\AppData\\Local\\Temp\\pip-install-zh6t99wg\\pygame_2f19fb3783ad4cb6ae6eb0ba7ee53046\\buildconfig\\vstools.py\", line 5, in <module>\n",
      "      from distutils.msvccompiler import MSVCCompiler, get_build_architecture\n",
      "  ModuleNotFoundError: No module named 'distutils.msvccompiler'\n",
      "  \n",
      "  During handling of the above exception, another exception occurred:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\91748\\AppData\\Local\\Temp\\pip-install-zh6t99wg\\pygame_2f19fb3783ad4cb6ae6eb0ba7ee53046\\setup.py\", line 388, in <module>\n",
      "      buildconfig.config.main(AUTO_CONFIG)\n",
      "    File \"C:\\Users\\91748\\AppData\\Local\\Temp\\pip-install-zh6t99wg\\pygame_2f19fb3783ad4cb6ae6eb0ba7ee53046\\buildconfig\\config.py\", line 234, in main\n",
      "      deps = CFG.main(**kwds)\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\91748\\AppData\\Local\\Temp\\pip-install-zh6t99wg\\pygame_2f19fb3783ad4cb6ae6eb0ba7ee53046\\buildconfig\\config_win.py\", line 511, in main\n",
      "      return setup_prebuilt_sdl2(prebuilt_dir)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\91748\\AppData\\Local\\Temp\\pip-install-zh6t99wg\\pygame_2f19fb3783ad4cb6ae6eb0ba7ee53046\\buildconfig\\config_win.py\", line 471, in setup_prebuilt_sdl2\n",
      "      DEPS.configure()\n",
      "    File \"C:\\Users\\91748\\AppData\\Local\\Temp\\pip-install-zh6t99wg\\pygame_2f19fb3783ad4cb6ae6eb0ba7ee53046\\buildconfig\\config_win.py\", line 338, in configure\n",
      "      from buildconfig import vstools\n",
      "    File \"C:\\Users\\91748\\AppData\\Local\\Temp\\pip-install-zh6t99wg\\pygame_2f19fb3783ad4cb6ae6eb0ba7ee53046\\buildconfig\\vstools.py\", line 5, in <module>\n",
      "      from distutils.msvccompiler import MSVCCompiler, get_build_architecture\n",
      "  ModuleNotFoundError: No module named 'distutils.msvccompiler'\n",
      "  Making dir :prebuilt_downloads:\n",
      "  Downloading... https://www.libsdl.org/release/SDL2-devel-2.0.16-VC.zip 13d952c333f3c2ebe9b7bc0075b4ad2f784e7584\n",
      "  Unzipping :prebuilt_downloads\\SDL2-devel-2.0.16-VC.zip:\n",
      "  Downloading... https://www.libsdl.org/projects/SDL_image/release/SDL2_image-devel-2.0.5-VC.zip 137f86474691f4e12e76e07d58d5920c8d844d5b\n",
      "  Unzipping :prebuilt_downloads\\SDL2_image-devel-2.0.5-VC.zip:\n",
      "  Downloading... https://www.libsdl.org/projects/SDL_ttf/release/SDL2_ttf-devel-2.0.15-VC.zip 1436df41ebc47ac36e02ec9bda5699e80ff9bd27\n",
      "  Unzipping :prebuilt_downloads\\SDL2_ttf-devel-2.0.15-VC.zip:\n",
      "  Downloading... https://www.libsdl.org/projects/SDL_mixer/release/SDL2_mixer-devel-2.0.4-VC.zip 9097148f4529cf19f805ccd007618dec280f0ecc\n",
      "  Unzipping :prebuilt_downloads\\SDL2_mixer-devel-2.0.4-VC.zip:\n",
      "  Downloading... https://www.pygame.org/ftp/jpegsr9d.zip ed10aa2b5a0fcfe74f8a6f7611aeb346b06a1f99\n",
      "  Unzipping :prebuilt_downloads\\jpegsr9d.zip:\n",
      "  Downloading... https://pygame.org/ftp/prebuilt-x64-pygame-1.9.2-20150922.zip 3a5af3427b3aa13a0aaf5c4cb08daaed341613ed\n",
      "  Unzipping :prebuilt_downloads\\prebuilt-x64-pygame-1.9.2-20150922.zip:\n",
      "  copying into .\\prebuilt-x64\n",
      "  Path for SDL: prebuilt-x64\\SDL2-2.0.16\n",
      "  ...Library directory for SDL: prebuilt-x64/SDL2-2.0.16/lib/x64\n",
      "  ...Include directory for SDL: prebuilt-x64/SDL2-2.0.16/include\n",
      "  Path for FONT: prebuilt-x64\\SDL2_ttf-2.0.15\n",
      "  ...Library directory for FONT: prebuilt-x64/SDL2_ttf-2.0.15/lib/x64\n",
      "  ...Include directory for FONT: prebuilt-x64/SDL2_ttf-2.0.15/include\n",
      "  Path for IMAGE: prebuilt-x64\\SDL2_image-2.0.5\n",
      "  ...Library directory for IMAGE: prebuilt-x64/SDL2_image-2.0.5/lib/x64\n",
      "  ...Include directory for IMAGE: prebuilt-x64/SDL2_image-2.0.5/include\n",
      "  Path for MIXER: prebuilt-x64\\SDL2_mixer-2.0.4\n",
      "  ...Library directory for MIXER: prebuilt-x64/SDL2_mixer-2.0.4/lib/x64\n",
      "  ...Include directory for MIXER: prebuilt-x64/SDL2_mixer-2.0.4/include\n",
      "  Path for PORTMIDI: prebuilt-x64\n",
      "  ...Library directory for PORTMIDI: prebuilt-x64/lib\n",
      "  ...Include directory for PORTMIDI: prebuilt-x64/include\n",
      "  DLL for SDL2: prebuilt-x64/SDL2-2.0.16/lib/x64/SDL2.dll\n",
      "  DLL for SDL2_ttf: prebuilt-x64/SDL2_ttf-2.0.15/lib/x64/SDL2_ttf.dll\n",
      "  DLL for SDL2_image: prebuilt-x64/SDL2_image-2.0.5/lib/x64/SDL2_image.dll\n",
      "  DLL for SDL2_mixer: prebuilt-x64/SDL2_mixer-2.0.4/lib/x64/SDL2_mixer.dll\n",
      "  DLL for portmidi: prebuilt-x64/lib/portmidi.dll\n",
      "  Path for FREETYPE not found.\n",
      "  ...Found include dir but no library dir in prebuilt-x64.\n",
      "  Path for PNG not found.\n",
      "  ...Found include dir but no library dir in prebuilt-x64.\n",
      "  Path for JPEG not found.\n",
      "  ...Found include dir but no library dir in prebuilt-x64.\n",
      "  DLL for freetype: prebuilt-x64/SDL2_ttf-2.0.15/lib/x64/libfreetype-6.dll\n",
      "  \n",
      "  ---\n",
      "  For help with compilation see:\n",
      "      https://www.pygame.org/wiki/CompileWindows\n",
      "  To contribute to pygame development see:\n",
      "      https://www.pygame.org/contribute.html\n",
      "  ---\n",
      "  \n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install gym[classic_control]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c49d7dc-10da-48ec-b48b-e389d31b26c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\91748\\.conda\\envs\\rl_env\\lib\\site-packages (25.0)\n",
      "Collecting pip\n",
      "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\91748\\.conda\\envs\\rl_env\\lib\\site-packages (75.8.0)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-78.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: wheel in c:\\users\\91748\\.conda\\envs\\rl_env\\lib\\site-packages (0.45.1)\n",
      "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 11.3 MB/s eta 0:00:00\n",
      "Downloading setuptools-78.1.0-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 10.6 MB/s eta 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\91748\\.conda\\envs\\rl_env\\python.exe -m pip install --upgrade pip setuptools wheel\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip setuptools wheel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e44332-b10a-4bd1-bb51-d418c364f7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\91748\\.conda\\envs\\rl_env\\lib\\site-packages (25.0.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\91748\\.conda\\envs\\rl_env\\lib\\site-packages (78.1.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\91748\\.conda\\envs\\rl_env\\lib\\site-packages (0.45.1)\n"
     ]
    }
   ],
   "source": [
    "!C:\\Users\\91748\\.conda\\envs\\rl_env\\python.exe -m pip install --upgrade pip setuptools wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64946977-76e5-471c-97a7-eed8ccb61e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygame\n",
      "  Downloading pygame-2.6.1-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Downloading pygame-2.6.1-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.1/10.6 MB 13.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.7/10.6 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.1/10.6 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.4/10.6 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 12.0 MB/s eta 0:00:00\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-2.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pygame --pre --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4faccea5-2e29-4c20-913d-0fe9b0bf5fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in c:\\users\\91748\\.conda\\envs\\rl_env\\lib\\site-packages (78.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install setuptools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bfac151-64a9-4743-b743-8fbc8c6eb22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.24.4 in c:\\users\\91748\\.conda\\envs\\rl_env\\lib\\site-packages (1.24.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy==1.24.4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b587136a-729e-4ba1-8f1e-b77823640447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numba==0.58.0\n",
      "  Downloading numba-0.58.0-cp311-cp311-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba==0.58.0)\n",
      "  Downloading llvmlite-0.41.1-cp311-cp311-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: numpy<1.26,>=1.21 in c:\\users\\91748\\.conda\\envs\\rl_env\\lib\\site-packages (from numba==0.58.0) (1.24.4)\n",
      "Downloading numba-0.58.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 1.0/2.6 MB 12.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.1/2.6 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 4.3 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.41.1-cp311-cp311-win_amd64.whl (28.1 MB)\n",
      "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.4/28.1 MB 12.2 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.7/28.1 MB 11.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 7.3/28.1 MB 11.9 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 9.7/28.1 MB 11.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 12.1/28.1 MB 11.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 14.4/28.1 MB 11.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 17.0/28.1 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 19.4/28.1 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 21.8/28.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 24.1/28.1 MB 11.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 26.7/28.1 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.1/28.1 MB 11.6 MB/s eta 0:00:00\n",
      "Installing collected packages: llvmlite, numba\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.44.0\n",
      "    Uninstalling llvmlite-0.44.0:\n",
      "      Successfully uninstalled llvmlite-0.44.0\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.61.0\n",
      "    Uninstalling numba-0.61.0:\n",
      "      Successfully uninstalled numba-0.61.0\n",
      "Successfully installed llvmlite-0.41.1 numba-0.58.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numba==0.58.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c952eefc-a5c5-4e76-a819-3d9faae87bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.23.5\n",
      "  Using cached numpy-1.23.5-cp311-cp311-win_amd64.whl.metadata (2.3 kB)\n",
      "Using cached numpy-1.23.5-cp311-cp311-win_amd64.whl (14.6 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "Successfully installed numpy-1.23.5\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.23.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b280637-a890-4750-8dc8-ef8f5b9e6481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
